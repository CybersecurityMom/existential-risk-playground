# Simple AI Safety Checklist (For Non-Experts)

This is a beginner-friendly checklist for thinking about AI systems,
especially ones that act on their own or touch important data.

You can use this as:
- A teaching tool
- A workshop handout
- A starting point for deeper conversations

---

## 1. What is this system allowed to do?

- Can it read data?
- Can it send messages?
- Can it change settings?
- Can it move money or make purchases?
- Can it control other tools or systems?

If you can't answer this clearly, you are not ready to trust it.

---

## 2. Who can stop it, and how?

- Is there a clear “off switch” or kill switch?
- Can a human easily undo its actions?
- Is there a person (not just a team name) responsible for this system?

If no one owns it, no one is truly watching it.

---

## 3. What happens if it makes a mistake?

- Does it touch live customer data?
- Can it break something important if it guesses wrong?
- Will a human review its output before anything serious happens?

High-impact actions should never be fully automatic at the start.

---

## 4. What is it optimising for?

- Speed?
- Cost?
- Clicks and engagement?
- “Accuracy” based on some training data?

Ask yourself: **If this system chased that goal too hard, what could go wrong?**

---

## 5. How will you know if it’s misbehaving?

- Do you have logs?
- Can you see what it did yesterday?
- Are there alerts for unusual activity?
- Is someone actually looking at those alerts?

No visibility = no safety.

---

This checklist will not catch everything, but it will:
- Slow you down enough to think.
- Give you words to ask better questions.
- Help you explain risk to people who are not technical.

That is where real safety starts.
